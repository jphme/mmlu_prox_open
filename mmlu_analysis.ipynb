{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMLU-ProX-Lite Processing and Upload\n",
    "\n",
    "Process all language configs, filter by answerability, and upload to HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in to HuggingFace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Load environment variables and login to HuggingFace\n",
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
    "login(token=HF_TOKEN)\n",
    "print(\"Logged in to HuggingFace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total questions: 588\n",
      "Answerable questions: 470\n"
     ]
    }
   ],
   "source": [
    "# Load classified dataset and create answerable question IDs set\n",
    "mmlu_classified = load_from_disk(\"mmlu_prox_classified\")\n",
    "df_answerable = pd.DataFrame({\n",
    "    \"index\": mmlu_classified[\"question_id\"],\n",
    "    \"is_answerable\": [1 if x else 0 for x in mmlu_classified[\"is_answerable\"]],\n",
    "})\n",
    "answerable_question_ids = set(\n",
    "    df_answerable[df_answerable[\"is_answerable\"] == 1][\"index\"]\n",
    ")\n",
    "\n",
    "print(f\"Total questions: {len(df_answerable)}\")\n",
    "print(f\"Answerable questions: {len(answerable_question_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will process 29 language configs\n"
     ]
    }
   ],
   "source": [
    "# Define all language configs and processing functions\n",
    "configs = [\n",
    "    \"af\",\n",
    "    \"ar\",\n",
    "    \"bn\",\n",
    "    \"cs\",\n",
    "    \"de\",\n",
    "    \"en\",\n",
    "    \"es\",\n",
    "    \"fr\",\n",
    "    \"hi\",\n",
    "    \"hu\",\n",
    "    \"id\",\n",
    "    \"it\",\n",
    "    \"ja\",\n",
    "    \"ko\",\n",
    "    \"mr\",\n",
    "    \"ne\",\n",
    "    \"pt\",\n",
    "    \"ru\",\n",
    "    \"sr\",\n",
    "    \"sw\",\n",
    "    \"te\",\n",
    "    \"th\",\n",
    "    \"uk\",\n",
    "    \"ur\",\n",
    "    \"vi\",\n",
    "    \"wo\",\n",
    "    \"yo\",\n",
    "    \"zh\",\n",
    "    \"zu\",\n",
    "]\n",
    "\n",
    "\n",
    "def get_answer_text(example):\n",
    "    \"\"\"Extract actual answer text based on answer_index\"\"\"\n",
    "    answer_index = example[\"answer_index\"]\n",
    "    option_key = f\"option_{answer_index}\"\n",
    "    return example.get(option_key, example[\"answer\"])\n",
    "\n",
    "\n",
    "def process_config(config):\n",
    "    \"\"\"Process a single language config\"\"\"\n",
    "    dataset = load_dataset(\"li-lab/MMLU-ProX-Lite\", config, split=\"test\")\n",
    "    filtered = dataset.filter(lambda x: x[\"question_id\"] in answerable_question_ids)\n",
    "    filtered = filtered.map(lambda x: {**x, \"answer\": get_answer_text(x)})\n",
    "    columns_to_keep = [\n",
    "        \"question_id\",\n",
    "        \"question\",\n",
    "        \"answer\",\n",
    "        \"cot_content\",\n",
    "        \"category\",\n",
    "        \"src\",\n",
    "    ]\n",
    "    return filtered.select_columns(columns_to_keep)\n",
    "\n",
    "\n",
    "print(f\"Will process {len(configs)} language configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing af...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 7097.99 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 82771.20 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 56618.63 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8213.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  af: 470 questions\n",
      "Processing ar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 18474.78 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 165497.97 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 69040.11 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9119.82 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ar: 470 questions\n",
      "Processing bn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 12224.73 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 96142.63 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 45287.21 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8244.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bn: 470 questions\n",
      "Processing cs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 10256.45 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 82101.63 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 53821.24 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9421.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cs: 470 questions\n",
      "Processing de...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 48373.98 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 7710.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  de: 470 questions\n",
      "Processing en...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 44430.55 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8137.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  en: 470 questions\n",
      "Processing es...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 19785.79 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 160385.69 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 55534.93 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9697.72 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  es: 470 questions\n",
      "Processing fr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 11625.47 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 120440.04 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 49419.90 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8332.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  fr: 470 questions\n",
      "Processing hi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 10800.92 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 128130.23 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 47001.27 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8394.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hi: 470 questions\n",
      "Processing hu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 13999.68 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 141348.62 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 50364.54 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8514.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hu: 470 questions\n",
      "Processing id...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 9082.79 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 98756.69 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 46358.10 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9355.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id: 470 questions\n",
      "Processing it...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 9139.62 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 53358.95 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 33645.99 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8779.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  it: 470 questions\n",
      "Processing ja...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 10921.85 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 104070.00 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 67369.17 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8065.21 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ja: 470 questions\n",
      "Processing ko...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 17861.13 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 208738.95 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 41593.60 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8834.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ko: 470 questions\n",
      "Processing mr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 5808.14 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 133102.20 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 53492.05 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 4599.05 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  mr: 470 questions\n",
      "Processing ne...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 19509.69 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 180255.13 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 53989.73 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9081.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ne: 470 questions\n",
      "Processing pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 20940.11 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 192796.34 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 77591.65 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 10006.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  pt: 470 questions\n",
      "Processing ru...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 18304.32 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 183801.67 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 39582.24 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8917.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ru: 470 questions\n",
      "Processing sr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 28880.71 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 189799.20 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 70605.52 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9421.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sr: 470 questions\n",
      "Processing sw...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 16117.77 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 146966.85 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 59556.89 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9042.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sw: 470 questions\n",
      "Processing te...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 13971.03 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 114666.67 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 47657.94 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8398.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  te: 470 questions\n",
      "Processing th...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 15096.73 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 182942.72 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 45216.63 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 7990.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  th: 470 questions\n",
      "Processing uk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 9979.65 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 112923.57 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 45591.95 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8316.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  uk: 470 questions\n",
      "Processing ur...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 9519.84 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 125241.25 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 46361.58 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8388.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ur: 470 questions\n",
      "Processing vi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 9124.29 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 116756.65 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 45275.57 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8238.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  vi: 470 questions\n",
      "Processing wo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 19520.06 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 190106.43 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 59843.03 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8714.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  wo: 470 questions\n",
      "Processing yo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 9594.19 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 123919.74 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 44357.03 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8328.89 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  yo: 470 questions\n",
      "Processing zh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 20528.69 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 117011.47 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 79382.35 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 9956.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  zh: 470 questions\n",
      "Processing zu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating validation split: 100%|██████████| 70/70 [00:00<00:00, 10925.51 examples/s]\n",
      "Generating test split: 100%|██████████| 588/588 [00:00<00:00, 138483.39 examples/s]\n",
      "Filter: 100%|██████████| 588/588 [00:00<00:00, 50485.16 examples/s]\n",
      "Map: 100%|██████████| 470/470 [00:00<00:00, 8613.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  zu: 470 questions\n",
      "Successfully processed 29 configs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all configs\n",
    "processed_datasets = {}\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"Processing {config}...\")\n",
    "    try:\n",
    "        processed = process_config(config)\n",
    "        processed_datasets[config] = processed\n",
    "        print(f\"  {config}: {len(processed)} questions\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing {config}: {e}\")\n",
    "\n",
    "print(f\"Successfully processed {len(processed_datasets)} configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dictionary created with 29 configs\n",
      "Uploading to jphme/MMLU-ProX-Lite-open...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 209.52ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.23s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 454.52ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 445.59ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 282.24ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 409.16ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.96s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 537.66ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 513.88ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 533.97ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.48s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 568.80ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 427.60ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 429.35ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 361.42ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.78s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 444.69ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 471.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 254.18ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.80s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 358.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 260.08ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 403.69ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.79s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 548.78ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.75s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 508.09ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 803.20ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:03<00:00,  3.17s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 409.84ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 429.39ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 807.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.97s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 781.79ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 461.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.83s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 918.39ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.76s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 269.18ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 135.83ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload completed!\n"
     ]
    }
   ],
   "source": [
    "# Upload to HuggingFace\n",
    "dataset_dict = DatasetDict(processed_datasets)\n",
    "\n",
    "print(f\"Dataset dictionary created with {len(dataset_dict)} configs\")\n",
    "print(\"Uploading to jphme/MMLU-ProX-Lite-open...\")\n",
    "\n",
    "dataset_dict.push_to_hub(\"jphme/MMLU-ProX-Lite-open\", token=HF_TOKEN, private=False)\n",
    "\n",
    "print(\"Upload completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Summary:\n",
      "af: 470 questions\n",
      "ar: 470 questions\n",
      "bn: 470 questions\n",
      "cs: 470 questions\n",
      "de: 470 questions\n",
      "en: 470 questions\n",
      "es: 470 questions\n",
      "fr: 470 questions\n",
      "hi: 470 questions\n",
      "hu: 470 questions\n",
      "id: 470 questions\n",
      "it: 470 questions\n",
      "ja: 470 questions\n",
      "ko: 470 questions\n",
      "mr: 470 questions\n",
      "ne: 470 questions\n",
      "pt: 470 questions\n",
      "ru: 470 questions\n",
      "sr: 470 questions\n",
      "sw: 470 questions\n",
      "te: 470 questions\n",
      "th: 470 questions\n",
      "uk: 470 questions\n",
      "ur: 470 questions\n",
      "vi: 470 questions\n",
      "wo: 470 questions\n",
      "yo: 470 questions\n",
      "zh: 470 questions\n",
      "zu: 470 questions\n",
      "\n",
      "Total configs: 29\n",
      "Dataset uploaded to: jphme/MMLU-ProX-Lite-open\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"Processing Summary:\")\n",
    "for config, dataset in processed_datasets.items():\n",
    "    print(f\"{config}: {len(dataset)} questions\")\n",
    "\n",
    "print(f\"\\nTotal configs: {len(processed_datasets)}\")\n",
    "print(f\"Dataset uploaded to: jphme/MMLU-ProX-Lite-open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 470/470 [00:00<00:00, 7014.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated answer column with actual answer text\n",
      "Sample answers:\n",
      "Question 72: Answer index 6 -> '62 Mann'\n",
      "Question 73: Answer index 3 -> 'Kommunikation'\n",
      "Question 74: Answer index 4 -> 'Watermans Anteil betrug 5.500 $ und Coles Anteil betrug 4.900 $'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Overwrite \"answer\" column with the actual answer text from option_i\n",
    "# where i is the answer_index\n",
    "\n",
    "\n",
    "def get_answer_text(example):\n",
    "    \"\"\"Extract the actual answer text based on answer_index\"\"\"\n",
    "    answer_index = example[\"answer_index\"]\n",
    "    option_key = f\"option_{answer_index}\"\n",
    "    return example.get(\n",
    "        option_key, example[\"answer\"]\n",
    "    )  # fallback to original if option not found\n",
    "\n",
    "\n",
    "# Map the dataset to replace answer with actual answer text\n",
    "filtered_mmlu_prox_lite = filtered_mmlu_prox_lite.map(\n",
    "    lambda example: {**example, \"answer\": get_answer_text(example)}\n",
    ")\n",
    "\n",
    "print(\"Updated answer column with actual answer text\")\n",
    "print(\"Sample answers:\")\n",
    "for i in range(min(3, len(filtered_mmlu_prox_lite))):\n",
    "    example = filtered_mmlu_prox_lite[i]\n",
    "    print(\n",
    "        f\"Question {example['question_id']}: Answer index {example['answer_index']} -> '{example['answer']}'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 72,\n",
       " 'question': 'Ermitteln Sie die Anzahl der Männer, die benötigt werden, um ein Boot in 77 Tagen zu bauen, wenn 36 Mann 132 Tage brauchen, um eines zu bauen.',\n",
       " 'answer': '62 Mann',\n",
       " 'cot_content': '',\n",
       " 'category': 'business',\n",
       " 'src': 'stemez-Business'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
