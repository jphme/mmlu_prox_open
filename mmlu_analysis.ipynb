{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# MMLU-ProX-Lite Processing and Upload\n\nProcess all language configs, filter by answerability, and upload to HuggingFace."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport pandas as pd\nfrom datasets import load_dataset, load_from_disk, DatasetDict\nfrom dotenv import load_dotenv\nfrom huggingface_hub import login\n\n# Load environment variables and login to HuggingFace\nload_dotenv()\nHF_TOKEN = os.getenv('HF_TOKEN')\nlogin(token=HF_TOKEN)\nprint(\"Logged in to HuggingFace\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load classified dataset and create answerable question IDs set\nmmlu_classified = load_from_disk(\"mmlu_prox_classified\")\ndf_answerable = pd.DataFrame({\n    \"index\": mmlu_classified[\"question_id\"],\n    \"is_answerable\": [1 if x else 0 for x in mmlu_classified[\"is_answerable\"]],\n})\nanswerable_question_ids = set(df_answerable[df_answerable['is_answerable'] == 1]['index'])\n\nprint(f\"Total questions: {len(df_answerable)}\")\nprint(f\"Answerable questions: {len(answerable_question_ids)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Define all language configs and processing functions\nconfigs = [\n    \"af\", \"ar\", \"bn\", \"cs\", \"de\", \"en\", \"es\", \"fr\", \"hi\", \"hu\",\n    \"id\", \"it\", \"ja\", \"ko\", \"mr\", \"ne\", \"pt\", \"ru\", \"sr\", \"sw\",\n    \"te\", \"th\", \"uk\", \"ur\", \"vi\", \"wo\", \"yo\", \"zh\", \"zu\"\n]\n\ndef get_answer_text(example):\n    \"\"\"Extract actual answer text based on answer_index\"\"\"\n    answer_index = example['answer_index']\n    option_key = f'option_{answer_index}'\n    return example.get(option_key, example['answer'])\n\ndef process_config(config):\n    \"\"\"Process a single language config\"\"\"\n    dataset = load_dataset(\"li-lab/MMLU-ProX-Lite\", config, split=\"test\")\n    filtered = dataset.filter(lambda x: x['question_id'] in answerable_question_ids)\n    filtered = filtered.map(lambda x: {**x, 'answer': get_answer_text(x)})\n    columns_to_keep = [\"question_id\", \"question\", \"answer\", \"cot_content\", \"category\", \"src\"]\n    return filtered.select_columns(columns_to_keep)\n\nprint(f\"Will process {len(configs)} language configs\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Process all configs\nprocessed_datasets = {}\n\nfor config in configs:\n    print(f\"Processing {config}...\")\n    try:\n        processed = process_config(config)\n        processed_datasets[config] = processed\n        print(f\"  {config}: {len(processed)} questions\")\n    except Exception as e:\n        print(f\"  Error processing {config}: {e}\")\n\nprint(f\"Successfully processed {len(processed_datasets)} configs\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Upload to HuggingFace\ndataset_dict = DatasetDict(processed_datasets)\n\nprint(f\"Dataset dictionary created with {len(dataset_dict)} configs\")\nprint(\"Uploading to jphme/MMLU-ProX-Lite-open...\")\n\ndataset_dict.push_to_hub(\n    \"jphme/MMLU-ProX-Lite-open\",\n    token=HF_TOKEN,\n    private=False\n)\n\nprint(\"Upload completed!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary\nprint(\"Processing Summary:\")\nfor config, dataset in processed_datasets.items():\n    print(f\"{config}: {len(dataset)} questions\")\n\nprint(f\"\\nTotal configs: {len(processed_datasets)}\")\nprint(f\"Dataset uploaded to: jphme/MMLU-ProX-Lite-open\")"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 470/470 [00:00<00:00, 7014.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated answer column with actual answer text\n",
      "Sample answers:\n",
      "Question 72: Answer index 6 -> '62 Mann'\n",
      "Question 73: Answer index 3 -> 'Kommunikation'\n",
      "Question 74: Answer index 4 -> 'Watermans Anteil betrug 5.500 $ und Coles Anteil betrug 4.900 $'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Overwrite \"answer\" column with the actual answer text from option_i\n",
    "# where i is the answer_index\n",
    "\n",
    "\n",
    "def get_answer_text(example):\n",
    "    \"\"\"Extract the actual answer text based on answer_index\"\"\"\n",
    "    answer_index = example[\"answer_index\"]\n",
    "    option_key = f\"option_{answer_index}\"\n",
    "    return example.get(\n",
    "        option_key, example[\"answer\"]\n",
    "    )  # fallback to original if option not found\n",
    "\n",
    "\n",
    "# Map the dataset to replace answer with actual answer text\n",
    "filtered_mmlu_prox_lite = filtered_mmlu_prox_lite.map(\n",
    "    lambda example: {**example, \"answer\": get_answer_text(example)}\n",
    ")\n",
    "\n",
    "print(\"Updated answer column with actual answer text\")\n",
    "print(\"Sample answers:\")\n",
    "for i in range(min(3, len(filtered_mmlu_prox_lite))):\n",
    "    example = filtered_mmlu_prox_lite[i]\n",
    "    print(\n",
    "        f\"Question {example['question_id']}: Answer index {example['answer_index']} -> '{example['answer']}'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question_id': 72,\n",
       " 'question': 'Ermitteln Sie die Anzahl der Männer, die benötigt werden, um ein Boot in 77 Tagen zu bauen, wenn 36 Mann 132 Tage brauchen, um eines zu bauen.',\n",
       " 'answer': '62 Mann',\n",
       " 'cot_content': '',\n",
       " 'category': 'business',\n",
       " 'src': 'stemez-Business'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}